{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MNISTConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # this is the place where you instantiate all your modules\n",
    "        # you can later access them using the same names you've given them in\n",
    "        # here\n",
    "        super(MNISTConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    # it's the forward function that defines the network structure\n",
    "    # we're accepting only a single input in here, but if you want,\n",
    "    # feel free to use more\n",
    "    def forward(self, input):\n",
    "        x = self.pool1(F.relu(self.conv1(input)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # in your model definition you can go full crazy and use arbitrary\n",
    "        # python code to define your model structure\n",
    "        # all these are perfectly legal, and will be handled correctly\n",
    "        # by autograd:\n",
    "        # if x.gt(0) > x.numel() / 2:\n",
    "        #      ...\n",
    "        #\n",
    "        # you can even do a loop and reuse the same module inside it\n",
    "        # modules no longer hold ephemeral state, so you can use them\n",
    "        # multiple times during your forward pass\n",
    "        # while x.norm(2) < 10:\n",
    "        #    x = self.conv1(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTConvNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MNISTConvNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "out = net(input)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3275, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "target = torch.tensor([3], dtype=torch.long)\n",
    "loss_fn = nn.CrossEntropyLoss()  # LogSoftmax + ClassNLL Loss\n",
    "err = loss_fn(out, target)\n",
    "err.backward()\n",
    "\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 5, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 5, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.grad.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NllLossBackward at 0x7f4b2c0741d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printnorm(self, input, output):\n",
    "    # input is a tuple of packed inputs\n",
    "    # output is a Tensor. output.data is the Tensor we are interested\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('')\n",
    "    print('input: ', type(input))\n",
    "    print('input: ', input)\n",
    "    print('input len: ', len(input))\n",
    "    print('input[0]: ', type(input[0]))\n",
    "    print('output: ', type(output))\n",
    "    print('')\n",
    "    print('input size:', input[0].size())\n",
    "    print('output size:', output.data.size())\n",
    "    print('output norm:', output.data.norm())\n",
    "\n",
    "\n",
    "# net.conv2.register_forward_hook(printnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input:  (tensor([[[[-0.4550,  0.2048,  1.2065, -1.0196,  0.5834, -0.2306,  1.9071,\n",
      "           -0.0456,  0.4880,  1.4691,  0.8684, -2.0982, -1.1827, -2.1608,\n",
      "            1.4475,  0.9553, -1.2447,  0.5514,  1.5241,  0.4140,  1.2250,\n",
      "            0.4753,  0.2571,  0.2183, -2.4382, -0.9364, -0.4046,  0.1939],\n",
      "          [-0.6125, -1.1245,  0.2525,  1.3134, -1.9491,  1.1396, -1.6473,\n",
      "           -2.5672,  0.4604,  0.9389, -0.3131, -1.4419,  0.1234,  1.8143,\n",
      "           -1.3185, -0.2337, -0.3829,  0.3574, -0.6424, -0.7010,  0.0533,\n",
      "           -1.7722, -2.4586,  1.1290,  0.8116,  1.9008,  0.4258,  1.7755],\n",
      "          [ 1.0200,  0.4956, -1.8514, -0.5587,  1.4646,  0.0534, -1.0389,\n",
      "            0.3969, -1.0605,  0.3829, -0.2759, -1.1400,  1.5830, -0.0952,\n",
      "            2.2370,  0.9062, -0.3771,  2.3235, -0.1593,  0.8163,  0.4470,\n",
      "           -1.7632, -1.2523, -0.3382, -0.4972, -0.3634,  1.3637,  1.1882],\n",
      "          [-1.6735,  1.1846, -0.2945,  0.9267, -1.1190,  1.1162, -0.2064,\n",
      "            0.8882,  1.8458,  1.3068, -0.0361, -0.5635,  1.6085,  1.0759,\n",
      "           -0.2516, -1.0257,  1.4688, -1.3580, -0.6394,  0.4614,  0.1920,\n",
      "            0.6084,  0.7575,  0.4640, -1.1301, -0.3783,  0.9052, -1.0717],\n",
      "          [ 0.6532,  1.3934, -0.7921,  0.3062,  0.1369, -0.2896, -0.9909,\n",
      "           -1.5516,  1.1246,  0.6615, -0.6311,  0.3463,  0.7233, -0.2022,\n",
      "           -1.7407, -0.7718,  1.0492,  1.4234, -0.9466,  0.8837,  0.1534,\n",
      "           -0.7482, -0.6886, -0.7731,  1.1962, -0.5519,  0.5991, -1.4924],\n",
      "          [-0.6466, -0.5353,  0.2409, -0.7982,  0.0854, -1.5112,  0.3869,\n",
      "           -0.4834,  1.0904, -1.6366, -1.2382,  0.3542,  0.3787, -0.2200,\n",
      "           -1.1957,  0.4083, -0.4317,  0.7088,  2.1983, -1.6222,  0.7801,\n",
      "           -1.1635, -0.1888,  0.0055,  1.1467,  0.5950,  0.5967, -1.3876],\n",
      "          [-0.5297, -0.5540, -0.0295,  0.0059, -0.3515,  0.6910, -0.9143,\n",
      "            0.0075,  0.1746,  0.8809,  0.0478,  0.1067, -1.1184,  1.1283,\n",
      "           -0.4314,  0.7065, -0.0501, -0.1492,  1.4056,  0.4496,  0.8685,\n",
      "           -1.4559, -0.9757, -1.1884,  1.1086, -0.1831,  1.8951,  0.2116],\n",
      "          [-0.0438,  0.7141, -0.5335, -1.8471, -0.2543,  1.7549, -1.4228,\n",
      "            1.1090,  2.0147,  0.3945,  0.8159,  1.2721,  1.6072, -0.3220,\n",
      "            0.0776,  0.5759,  0.2753, -0.3472,  0.6363, -0.0962, -1.1982,\n",
      "            0.9945,  0.5949, -1.0892,  0.9941,  0.3576, -0.3925,  0.4993],\n",
      "          [ 0.1477,  0.5901,  0.0561,  0.5276,  0.4328,  1.0214,  0.6182,\n",
      "           -0.9701,  2.5417,  0.3343,  1.3913, -1.6531, -1.5092, -0.1132,\n",
      "           -0.1258, -0.1815, -1.4814,  0.8918,  0.3297,  0.5783,  1.7284,\n",
      "            0.0772, -0.6629, -2.1070, -0.0365, -0.4656, -1.3466,  0.3973],\n",
      "          [ 1.0032,  0.9581,  2.8092,  1.7825, -0.3783,  0.1837,  0.0885,\n",
      "            0.0716,  0.0711, -0.9146,  0.1962,  0.2604,  0.0930, -1.5462,\n",
      "            0.2760, -1.4219, -1.4461, -2.0709, -0.4471,  2.4605,  0.2475,\n",
      "           -0.5335,  0.3561, -0.2775, -0.9699, -1.0921, -0.8596,  0.4397],\n",
      "          [-2.3466, -0.9843, -0.1992,  1.7406,  0.5217,  0.9831,  0.3915,\n",
      "            1.9932,  1.0009, -1.3061, -0.7681, -0.7268,  0.6390,  1.0353,\n",
      "           -0.2014,  0.9296, -0.8096,  0.9810, -0.7047,  0.8306,  0.5435,\n",
      "            0.8000, -0.1050, -1.0562,  1.4121, -0.4121,  0.2244,  0.4609],\n",
      "          [ 0.9650,  0.3088, -2.1976, -0.9534, -0.4116, -0.1766, -0.2007,\n",
      "            0.3046, -0.4138, -1.1497, -0.1281,  0.1984,  1.3513, -0.0186,\n",
      "            1.7317,  0.7036,  1.7403,  1.0098, -0.0153,  0.9834,  0.7722,\n",
      "            0.7726, -1.4923,  0.6556, -0.4364, -0.4664,  0.9183,  0.5000],\n",
      "          [ 0.0708,  0.7993, -0.3033, -0.8902,  1.0105, -0.2651,  0.9557,\n",
      "            0.0921,  0.3729, -0.6914, -0.6439,  1.0327, -1.9459,  0.6233,\n",
      "            0.8735,  0.2400,  0.7640, -0.8946,  0.8957,  0.7924, -0.8240,\n",
      "           -0.0102, -1.5540,  0.8247,  0.4257,  0.4668,  0.3921,  1.2753],\n",
      "          [-0.2425,  0.1738,  0.4337, -0.5969,  0.7704, -1.1880,  0.8404,\n",
      "           -0.5263,  1.1568,  0.2747, -1.1141,  0.7052,  2.1505, -0.2952,\n",
      "           -1.1094,  0.5299,  0.1392, -0.1280, -0.4357, -0.8114,  0.1870,\n",
      "            0.3926,  0.3205, -0.4245,  0.5181, -0.1296, -0.3511,  0.8433],\n",
      "          [-0.9199, -0.3506, -1.8011, -0.5938,  0.5257, -1.1377, -0.3313,\n",
      "            0.7680, -0.7340, -0.6230,  0.4671, -0.0881, -0.9052,  0.1707,\n",
      "            1.4880,  0.6447, -1.0376, -0.6074, -0.0504, -1.1779,  1.5671,\n",
      "            0.1363,  2.0918,  0.3047, -1.6872, -0.5575,  0.6604,  0.5140],\n",
      "          [-1.3116, -0.5208, -1.6249, -0.9420, -1.3552,  0.5635, -1.0594,\n",
      "           -0.7391,  0.4473, -0.5044,  0.2814, -0.3305,  1.1409, -0.9529,\n",
      "           -0.3690,  0.8227,  1.4457,  1.5641, -0.8317, -1.9805, -0.8844,\n",
      "            0.0841, -0.8757, -0.3221,  0.0528,  1.1429,  0.4404,  0.3279],\n",
      "          [-1.7004,  0.8299,  0.7980,  0.2360, -0.7781,  1.7409, -0.4513,\n",
      "            0.0646, -0.0242, -0.2664,  0.0855,  0.2503, -0.0509, -1.0139,\n",
      "            1.3735, -0.4815, -0.1685,  0.7655, -0.0990, -0.3208, -0.6500,\n",
      "            0.0466, -0.4502, -0.7802, -0.5953,  0.7426, -0.2921, -0.0847],\n",
      "          [-1.3153,  0.9685,  1.2462,  0.6518, -1.3505,  0.0800,  0.9306,\n",
      "            0.1706, -0.1865,  0.3669, -0.5783, -1.3912,  1.2209, -0.3473,\n",
      "            0.5221, -0.4425,  1.0057, -0.6807, -1.1294, -0.6690,  1.4324,\n",
      "           -0.5036, -0.8307, -0.5136, -1.8159, -0.9145,  2.0029, -0.2592],\n",
      "          [-0.8416,  0.3425, -0.0831,  0.4975,  0.2951,  1.8691,  0.7491,\n",
      "           -0.1976,  0.1225, -0.0524,  1.8390,  0.8868,  0.9948, -0.5058,\n",
      "            0.0792,  0.4236,  1.2237,  1.1525,  2.2901,  0.8096,  0.1553,\n",
      "           -0.5079, -1.4272, -0.0554,  1.4126,  0.1084,  0.8331,  0.5956],\n",
      "          [-1.0617, -0.1840,  0.5753,  1.0523,  0.5449, -0.6466, -0.1465,\n",
      "            1.2888, -1.6873,  1.2630,  0.5322, -0.0158,  0.0129, -0.0245,\n",
      "           -1.0079,  0.1664, -0.9174,  0.6499, -0.0688, -1.2428, -0.3246,\n",
      "           -0.6249, -0.8041, -1.0485,  0.3153, -0.4193,  0.1108, -0.2234],\n",
      "          [-1.0480,  1.1046, -1.4933, -0.8363,  0.0220, -0.5200,  1.0081,\n",
      "           -1.6281,  1.1860,  0.1612,  0.1152,  1.6674, -0.3300,  0.0502,\n",
      "           -0.5671,  0.4782, -0.9559,  0.0485, -0.2105, -1.5141, -1.9169,\n",
      "           -0.7383,  0.0156,  0.8114,  1.2648, -0.0140,  1.8984,  0.4338],\n",
      "          [-0.3065, -0.4239,  0.3681, -0.3872, -0.6488,  0.0237, -0.2261,\n",
      "            0.7067,  1.1341,  1.2263, -1.3630, -0.4160, -0.7808, -2.0492,\n",
      "           -1.3291, -0.6746,  0.8948, -1.0709, -0.9350, -1.9851, -0.4327,\n",
      "           -0.0485, -0.0441,  0.8179, -1.1204, -0.4178, -1.1637,  0.7489],\n",
      "          [ 0.2565, -0.8948, -0.7936, -0.6571, -0.0541, -1.6629, -1.3906,\n",
      "            2.2704, -0.6466,  0.2112,  0.3331,  0.1763, -0.5357,  0.8773,\n",
      "           -0.5154,  0.7035,  0.5995, -0.4039,  0.3041, -1.1156, -0.0474,\n",
      "            1.9271, -1.0199, -0.2056, -0.3520, -0.0207,  1.2245,  0.8948],\n",
      "          [-0.7304,  1.4161,  1.0463,  1.5366, -1.2824,  0.9041, -0.3195,\n",
      "           -0.8270,  0.8864,  0.2254, -0.7241, -1.6100, -0.2805,  1.7476,\n",
      "           -0.7868,  0.2222, -0.2472,  0.1282,  0.3555,  0.9186, -0.5741,\n",
      "           -0.0775, -0.4856,  3.5203, -0.3549, -0.3281, -1.9098, -1.2255],\n",
      "          [-0.1347, -0.3864, -0.0344,  0.3760, -0.2993, -1.0576,  0.4879,\n",
      "            0.4785, -0.7738, -0.6203, -2.0140, -0.8527,  1.2322, -0.8430,\n",
      "            0.3304, -1.0255,  0.4568,  0.2920,  0.8737, -1.0651, -0.5299,\n",
      "            0.5988, -0.9945,  0.0733, -0.0943, -1.9165, -1.4539, -0.6595],\n",
      "          [ 0.5254, -0.0936, -0.3831,  0.2972, -1.0241,  1.5047, -1.7371,\n",
      "           -1.0033, -1.2734, -1.1539, -0.9480, -1.2040, -0.8061,  0.9415,\n",
      "            1.3535,  0.5938,  0.5960, -1.1684, -0.1743,  1.4411, -1.7743,\n",
      "           -0.3286,  0.9513, -1.0107, -0.9517, -0.6322,  1.3636,  0.7603],\n",
      "          [ 1.1566, -0.9532,  0.5167, -0.9806, -0.5138,  0.7057, -0.9193,\n",
      "            0.3481,  1.1105, -0.1750,  0.7183,  0.8349,  0.9303,  1.3871,\n",
      "            0.7513,  0.4852,  1.1117,  0.9242, -2.5570,  1.6336,  0.6401,\n",
      "            0.1013,  0.6226,  2.9169,  0.5963, -0.6075, -0.8000, -2.1146],\n",
      "          [-1.9621,  0.9660, -0.3857,  0.6233,  0.0353, -1.2977,  0.9731,\n",
      "           -1.9106, -0.4056,  1.0040, -1.3650,  0.0619, -1.3987,  0.3018,\n",
      "            0.3712,  0.5216,  0.6540, -0.9341,  1.4097,  0.7275, -0.0870,\n",
      "           -0.9670, -0.4283,  1.9287,  1.4909,  0.5937, -2.0947, -1.4317]]]]),)\n",
      "input len:  1\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([1, 1, 28, 28])\n",
      "output size: torch.Size([1, 10, 24, 24])\n",
      "output norm: tensor(43.4439)\n",
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([1, 10, 12, 12])\n",
      "output size: torch.Size([1, 20, 8, 8])\n",
      "output norm: tensor(14.6993)\n",
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input len:  1\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([1, 10, 12, 12])\n",
      "output size: torch.Size([1, 20, 8, 8])\n",
      "output norm: tensor(14.6993)\n"
     ]
    }
   ],
   "source": [
    "out = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f4b2c074790>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.register_forward_hook(printnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__constants__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_buffers', '_forward_hooks', '_forward_pre_hooks', '_get_name', '_load_from_state_dict', '_load_state_dict_pre_hooks', '_modules', '_named_members', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_version', 'add_module', 'apply', 'bias', 'buffers', 'children', 'conv2d_forward', 'cpu', 'cuda', 'dilation', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'groups', 'half', 'in_channels', 'kernel_size', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'out_channels', 'output_padding', 'padding', 'padding_mode', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_parameter', 'requires_grad_', 'reset_parameters', 'share_memory', 'state_dict', 'stride', 'to', 'train', 'training', 'transposed', 'type', 'weight', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "for m in net.children():\n",
    "    print(dir(m))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTConvNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Linear(in_features=320, out_features=50, bias=True)\n",
      "Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for m in net.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
