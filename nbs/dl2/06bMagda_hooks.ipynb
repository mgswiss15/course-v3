{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_03Magda import *\n",
    "from exp.nb_04Magda_corrected import *\n",
    "from exp.nb_05bMagda import *\n",
    "from exp.nb_06Magda import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, valid_x, valid_y, test_x, test_y = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, test_x = norm_all(train_x, valid_x, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_bunch = DataBunch(train_x, train_y, valid_x, valid_y, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Manual monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(SequentialModel, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.means = [[] for _ in layers]\n",
    "        self.stds = [[] for _ in layers]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for lidx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            self.means[lidx].append(x.mean().item())\n",
    "            self.stds[lidx].append(x.std().item())\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LearnerSequential(Learner):\n",
    "    def __init__(self, data_bunch, callback_list=[], layers=[]):\n",
    "        self.layers = layers\n",
    "        super(LearnerSequential, self).__init__(data_bunch, callback_list)\n",
    "    \n",
    "    def _get_model(self, **kwargs):\n",
    "        self.model = SequentialModel(self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "callback_list = [CudaCallback(torch.device('cuda')), ReshapeMnist(), LossCallback(), AccuracyCallback(), ParamScheduler('lr', 'fixed_sched', 0.5)]\n",
    "layer_list = [nn.Conv2d(1, 8, 5, padding=2, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, padding=1, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            Flatten(),\n",
    "            nn.Linear(32, 10)\n",
    "]\n",
    "learner_seq = LearnerSequential(mnist_bunch, callback_list, layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner_seq.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lidx, l in enumerate(learner_seq.model.means):\n",
    "    plt.plot(l, label=lidx)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for lidx, l in enumerate(learner_seq.model.stds):\n",
    "    plt.plot(l, label=lidx)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## pytorch hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "class LearnerCnn(Learner):\n",
    "    def _get_model(self, num_out=10):\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 5, padding=2, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, padding=1, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            Flatten(),\n",
    "            nn.Linear(32, num_out)\n",
    "        )\n",
    "        self.means = [[] for _ in self.model]\n",
    "        self.stds = [[] for _ in self.model]\n",
    "        for lidx, m in enumerate(self.model):\n",
    "            m.register_forward_hook(partial(self.append_stats, lidx))\n",
    "            \n",
    "    def append_stats(self, idx, mod, ins, outs):\n",
    "        self.means[idx].append(outs.mean().item())\n",
    "        self.stds[idx].append(outs.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "cb_list = [CudaCallback(device), ReshapeMnist(), LossCallback(), AccuracyCallback()]\n",
    "# cb_list.append(CombineScheduler('lr', [0.3, 0.7], ['cosine_sched', 'cosine_sched'], 0.01, 0.5, 0.01))\n",
    "learner_cnn = LearnerCnn(mnist_bunch, cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner_cnn.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for m in learner_cnn.means:\n",
    "    plt.plot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for m in learner_cnn.stds:\n",
    "    plt.plot(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inspect weights and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class WeightsMonitoringCallback(Callback):\n",
    "    def fit_begin(self):\n",
    "        self.learner.metrics['weights_mean'] = [[] for _ in self.learner.model.children()]\n",
    "        self.learner.metrics['weights_std'] = [[] for _ in self.learner.model.children()]\n",
    "        self.learner.metrics['weights_grad_mean'] = [[] for _ in self.learner.model.children()]\n",
    "        self.learner.metrics['weights__grad_std'] = [[] for _ in self.learner.model.children()]\n",
    "        \n",
    "    def before_optim_step(self):\n",
    "        for lidx, layer in enumerate(self.learner.model.children()):\n",
    "            try:\n",
    "                weight = layer.weight.detach()\n",
    "                self.learner.metrics['weights_mean'][lidx].append(weight.mean().item())\n",
    "                self.learner.metrics['weights_std'][lidx].append(weight.std().item())\n",
    "                self.learner.metrics['weights_grad_mean'][lidx].append(weight.grad.mean().item())\n",
    "                self.learner.metrics['weights__grad_std'][lidx].append(weight.grad.std().item())\n",
    "            except AttributeError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "cb_list = [CudaCallback(device), ReshapeMnist(), LossCallback(), AccuracyCallback(), WeightsMonitoringCallback()]\n",
    "# cb_list.append(CombineScheduler('lr', [0.3, 0.7], ['cosine_sched', 'cosine_sched'], 0.01, 0.5, 0.01))\n",
    "learner_cnn = LearnerCnn(mnist_bunch, cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner_cnn.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for weights in learner_cnn.metrics['weights_mean']:\n",
    "    plt.plot(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for weights in learner_cnn.metrics['weights_std']:\n",
    "    plt.plot(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hook class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_cnn = LearnerCnn(mnist_bunch, cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Hook():\n",
    "    def __init__(self, layer, hook_func):\n",
    "        self.hook = layer.register_forward_hook(hook_func)\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.remove()\n",
    "        \n",
    "    def remove(self):\n",
    "        self.hook.remove()\n",
    "        \n",
    "    @staticmethod\n",
    "    def forward_stats(self, inputs, outputs):\n",
    "        if not hasattr(self, 'output_stats'):\n",
    "            self.forward_stats = {'means': [], 'stds': []}\n",
    "        self.output_stats['means'].append(outputs.mean().item())\n",
    "        self.output_stats['stds'].append(outputs.std().item())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = [Hook(x, Hook.forward_stats) for x in learner_cnn.model.children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_cnn.fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lidx, layer in enumerate(learner_cnn.model.children()):\n",
    "    plt.plot(layer.forward_stats['means'], label=lidx)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hooks callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HooksCallback(Callback):\n",
    "    def fit_begin(self):\n",
    "        self.hooks = [Hook(x, Hook.forward_stats) for x in self.learner.model.children()]\n",
    "    \n",
    "    def fit_end(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "cb_list = [CudaCallback(device), ReshapeMnist(), LossCallback(), AccuracyCallback()]\n",
    "cb_list.append(HooksCallback())\n",
    "learner_cnn = LearnerCnn(mnist_bunch, cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  2.294724702835083 validation:  2.294064521789551\n",
      "train:  2.262110471725464 validation:  2.2482378482818604\n",
      "train:  2.2525384426116943 validation:  2.226407527923584\n",
      "train:  2.3146629333496094 validation:  2.3179354667663574\n",
      "train:  2.3042073249816895 validation:  2.3037664890289307\n",
      "Final accuracy: 0.106400\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013db07d0> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013db0810> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75a10> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75a90> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75b50> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75c50> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75d10> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75dd0> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75e90> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75f10> removing\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f9013d75fd0> removing\n"
     ]
    }
   ],
   "source": [
    "learner_cnn.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'means': [0.03696437180042267, 0.037063874304294586, 0.03648197650909424, 0.0361950546503067, 0.037466954439878464, 0.03745844215154648, 0.038411397486925125, 0.03806674852967262, 0.038821298629045486, 0.03871595114469528, 0.03770044445991516, 0.03909255191683769, 0.0406080037355423, 0.040049873292446136, 0.04147544503211975, 0.0454460047185421, 0.04423719644546509, 0.04502612352371216, 0.046562690287828445, 0.04781987518072128, 0.052782557904720306, 0.050199802964925766, 0.053444940596818924, 0.056484200060367584, 0.06119702011346817, 0.06612163782119751, 0.07296962291002274, 0.07601623237133026, 0.08375708758831024, 0.09531799703836441, 0.05292227119207382, 0.05444929003715515, 0.05246994271874428, 0.0566687174141407, 0.06018519401550293, 0.06624256819486618, 0.0739092156291008, 0.07959616929292679, 0.09257527440786362, 0.11484327167272568, 0.10340968519449234, -0.169892355799675, -0.16700275242328644, -0.15564754605293274, -0.16684943437576294, -0.16607481241226196, -0.16982094943523407, -0.171823188662529, -0.17104412615299225, -0.16795144975185394, -0.17380404472351074, -0.16687682271003723, -0.16602018475532532, -0.16758659482002258, -0.1555633544921875], 'stds': [0.6104164123535156, 0.6117250919342041, 0.6109938621520996, 0.612024188041687, 0.6166554093360901, 0.6184453368186951, 0.6234361529350281, 0.6252520084381104, 0.6300090551376343, 0.6331823468208313, 0.6352131962776184, 0.638170063495636, 0.646680474281311, 0.6508396863937378, 0.6603370904922485, 0.6760361194610596, 0.6822906136512756, 0.6935527324676514, 0.7088959813117981, 0.725236177444458, 0.751488447189331, 0.7654169201850891, 0.7731717228889465, 0.8040531873703003, 0.8429974913597107, 0.8945326805114746, 0.9615111351013184, 1.0316250324249268, 1.1295052766799927, 1.2647805213928223, 0.8998633623123169, 0.9087607860565186, 0.9255024194717407, 0.9352530241012573, 0.9733714461326599, 1.0273171663284302, 1.1014500856399536, 1.1987087726593018, 1.3408397436141968, 1.546162486076355, 1.5169880390167236, 1.8979312181472778, 1.8967533111572266, 1.8653819561004639, 1.8907711505889893, 1.8966436386108398, 1.902398705482483, 1.903367280960083, 1.90277099609375, 1.8977354764938354, 1.9057806730270386, 1.9002050161361694, 1.8935389518737793, 1.8979809284210205, 1.865783452987671]}\n"
     ]
    }
   ],
   "source": [
    "for layer in learner_cnn.model.children():\n",
    "    print(layer.forward_stats)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from IPython.display import display, Javascript\n",
    "def nb_auto_export():\n",
    "    display(Javascript(\"\"\"{\n",
    "const ip = IPython.notebook\n",
    "if (ip) {\n",
    "    ip.save_notebook()\n",
    "    console.log('a')\n",
    "    const s = `!python notebook2script.py ${ip.notebook_name}`\n",
    "    if (ip.kernel) { ip.kernel.execute(s) }\n",
    "}\n",
    "}\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_auto_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
